{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\n\nprint(\"This notebook was created using version 1.0.17 of the Azure ML SDK\")\nprint(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": "This notebook was created using version 1.0.17 of the Azure ML SDK\nYou are currently using version 1.0.17 of the Azure ML SDK\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nsubscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"da21a094-26a3-472f-991b-e2b11979af40\")\nresource_group = os.getenv(\"RESOURCE_GROUP\", default=\"mlservices\")\nworkspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"autoML\")",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\ntry:\n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n    # write the details of the workspace to a configuration file to the notebook library\n    ws.write_config()\n    print(\"Workspace configuration succeeded.\")\nexcept:\n    print(\"Workspace not accessible. Change your parameters or create a new workspace.\")",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Wrote the config file config.json to: /home/nbuser/library/aml_config/config.json\nWorkspace configuration succeeded.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.workspace import Workspace\nfrom azureml.core.experiment import Experiment\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nimport pandas as pd\nimport numpy as np\nfrom numpy import array\nimport logging\nimport warnings\n# Squash warning messages for cleaner output in the notebook\nwarnings.showwarning = lambda *args, **kwargs: None",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Retrieve workspace\nws = Workspace.from_config()\n\n# choose a name for the run history container in the workspace\nexperiment_name = 'automl-titanic'\n# project folder\nproject_folder = './sample_projects/automl-titanic'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Run History Name'] = experiment_name\npd.set_option('display.max_colwidth', -1)\noutputDf = pd.DataFrame(data = output, index = [''])\noutputDf.T",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Location</th>\n      <td>westeurope</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>./sample_projects/automl-titanic</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>mlservices</td>\n    </tr>\n    <tr>\n      <th>Run History Name</th>\n      <td>automl-titanic</td>\n    </tr>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.17</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>da21a094-26a3-472f-991b-e2b11979af40</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>autoML</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                       \nLocation           westeurope                          \nProject Directory  ./sample_projects/automl-titanic    \nResource Group     mlservices                          \nRun History Name   automl-titanic                      \nSDK version        1.0.17                              \nSubscription ID    da21a094-26a3-472f-991b-e2b11979af40\nWorkspace          autoML                              "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import ComputeTarget, AmlCompute\nprint(AmlCompute.supported_vmsizes(workspace=ws))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[{'name': 'Standard_D1', 'vCPUs': 1, 'memoryGB': 3.5}, {'name': 'Standard_D2', 'vCPUs': 2, 'memoryGB': 7.0}, {'name': 'Standard_D3', 'vCPUs': 4, 'memoryGB': 14.0}, {'name': 'Standard_D4', 'vCPUs': 8, 'memoryGB': 28.0}, {'name': 'Standard_D11', 'vCPUs': 2, 'memoryGB': 14.0}, {'name': 'Standard_D12', 'vCPUs': 4, 'memoryGB': 28.0}, {'name': 'Standard_D13', 'vCPUs': 8, 'memoryGB': 56.0}, {'name': 'Standard_D14', 'vCPUs': 16, 'memoryGB': 112.0}, {'name': 'Standard_D1_v2', 'vCPUs': 1, 'memoryGB': 3.5}, {'name': 'Standard_D2_v2', 'vCPUs': 2, 'memoryGB': 7.0}, {'name': 'Standard_D3_v2', 'vCPUs': 4, 'memoryGB': 14.0}, {'name': 'Standard_D4_v2', 'vCPUs': 8, 'memoryGB': 28.0}, {'name': 'Standard_D11_v2', 'vCPUs': 2, 'memoryGB': 14.0}, {'name': 'Standard_D12_v2', 'vCPUs': 4, 'memoryGB': 28.0}, {'name': 'Standard_D13_v2', 'vCPUs': 8, 'memoryGB': 56.0}, {'name': 'Standard_D14_v2', 'vCPUs': 16, 'memoryGB': 112.0}, {'name': 'Standard_DS1_v2', 'vCPUs': 1, 'memoryGB': 3.5}, {'name': 'Standard_DS2_v2', 'vCPUs': 2, 'memoryGB': 7.0}, {'name': 'Standard_DS3_v2', 'vCPUs': 4, 'memoryGB': 14.0}, {'name': 'Standard_DS4_v2', 'vCPUs': 8, 'memoryGB': 28.0}, {'name': 'Standard_DS5_v2', 'vCPUs': 16, 'memoryGB': 56.0}, {'name': 'Standard_DS11_v2', 'vCPUs': 2, 'memoryGB': 14.0}, {'name': 'Standard_DS12_v2', 'vCPUs': 4, 'memoryGB': 28.0}, {'name': 'Standard_DS13_v2', 'vCPUs': 8, 'memoryGB': 56.0}, {'name': 'Standard_DS14_v2', 'vCPUs': 16, 'memoryGB': 112.0}, {'name': 'Standard_DS15_v2', 'vCPUs': 20, 'memoryGB': 140.0}, {'name': 'Standard_NV6', 'vCPUs': 6, 'memoryGB': 56.0}, {'name': 'Standard_NV12', 'vCPUs': 12, 'memoryGB': 112.0}, {'name': 'Standard_NV24', 'vCPUs': 24, 'memoryGB': 224.0}, {'name': 'Standard_F2s_v2', 'vCPUs': 2, 'memoryGB': 4.0}, {'name': 'Standard_F4s_v2', 'vCPUs': 4, 'memoryGB': 8.0}, {'name': 'Standard_F8s_v2', 'vCPUs': 8, 'memoryGB': 16.0}, {'name': 'Standard_F16s_v2', 'vCPUs': 16, 'memoryGB': 32.0}, {'name': 'Standard_F32s_v2', 'vCPUs': 32, 'memoryGB': 64.0}, {'name': 'Standard_F64s_v2', 'vCPUs': 64, 'memoryGB': 128.0}, {'name': 'Standard_F72s_v2', 'vCPUs': 72, 'memoryGB': 144.0}, {'name': 'Standard_NC6s_v3', 'vCPUs': 6, 'memoryGB': 112.0}, {'name': 'Standard_NC12s_v3', 'vCPUs': 12, 'memoryGB': 224.0}, {'name': 'Standard_NC24rs_v3', 'vCPUs': 24, 'memoryGB': 448.0}, {'name': 'Standard_NC24s_v3', 'vCPUs': 24, 'memoryGB': 448.0}, {'name': 'Standard_NC6', 'vCPUs': 6, 'memoryGB': 56.0}, {'name': 'Standard_NC12', 'vCPUs': 12, 'memoryGB': 112.0}, {'name': 'Standard_NC24', 'vCPUs': 24, 'memoryGB': 224.0}, {'name': 'Standard_NC24r', 'vCPUs': 24, 'memoryGB': 224.0}, {'name': 'Standard_ND6s', 'vCPUs': 6, 'memoryGB': 112.0}, {'name': 'Standard_ND12s', 'vCPUs': 12, 'memoryGB': 224.0}, {'name': 'Standard_ND24rs', 'vCPUs': 24, 'memoryGB': 448.0}, {'name': 'Standard_ND24s', 'vCPUs': 24, 'memoryGB': 448.0}, {'name': 'Standard_NC6s_v2', 'vCPUs': 6, 'memoryGB': 112.0}, {'name': 'Standard_NC12s_v2', 'vCPUs': 12, 'memoryGB': 224.0}, {'name': 'Standard_NC24rs_v2', 'vCPUs': 24, 'memoryGB': 448.0}, {'name': 'Standard_NC24s_v2', 'vCPUs': 24, 'memoryGB': 448.0}]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute_target import ComputeTargetException\n\n# Choose a name for your CPU cluster\ncpu_cluster_name = \"cpucluster\"\n\n# Verify that cluster does not exist already\ntry:\n    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n    print(\"Found existing cpucluster\")\nexcept ComputeTargetException:\n    print(\"Creating new cpucluster\")\n    \n    # Specify the configuration for the new cluster\n    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n                                                           min_nodes=0,\n                                                           max_nodes=4)\n\n    # Create the cluster with the specified name and configuration\n    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n    \n    # Wait for the cluster to complete, show the output log\n    cpu_cluster.wait_for_completion(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.read_csv(\"TitanicTrain.csv\")\ndata[\"Survived\"].astype('category')\ndata.head()",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n      <th>HasCabin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.98</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.27</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.07</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.97</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.09</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Survived  Pclass  Sex   Age  SibSp  Parch  Fare  Embarked  Title  \\\n0  0         3       0   22.00  1      0     1.98   0         4       \n1  1         1       1   38.00  1      0     4.27   1         2       \n2  1         3       1   26.00  0      0     2.07   0         1       \n3  1         1       1   35.00  1      0     3.97   0         2       \n4  0         3       0   35.00  0      0     2.09   0         4       \n\n   FamilySize  IsAlone  HasCabin  \n0  2           0        0         \n1  2           0        1         \n2  1           1        0         \n3  2           0        1         \n4  1           1        0         "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline \ndisplay(data.describe().T)\ndata.boxplot(column=\"Fare\",      # Column to plot\n             by= \"Survived\",    # Column to split upon\n             figsize= (8,8))    # Figure size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = data.drop(columns=[\"Survived\",\"SibSp\",\"Parch\",\"FamilySize\"])\ny = array(data[\"Survived\"])",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.1,\n                                                    stratify = y)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(801, 8) (801,)\n(90, 8) (90,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_config = AutoMLConfig(task = 'classification',\n                             debug_log = 'automl_errors.log',\n                             primary_metric = 'accuracy',\n                             iteration_timeout_minutes = 5,\n                             iterations = 10,\n                             verbosity = logging.INFO,\n                             X = X_train, \n                             y = y_train,\n                             X_valid = X_test,\n                             y_valid = y_test,\n                             model_explainability=True,\n                             path=project_folder)",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running on local machine\nParent Run ID: AutoML_3ce55bce-18ab-4181-8449-5676bd4b22ce\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   ",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.core._multiarray_umath'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
          ]
        },
        {
          "output_type": "stream",
          "text": "StandardScalerWrapper LightGBM                 100.0000    0:00:39       0.8444    0.8444\n         1   MaxAbsScaler LightGBM                          100.0000    0:00:39       0.8444    0.8444\n         2   MinMaxScaler LightGBM                          100.0000    0:00:36       0.8444    0.8444\n         3   StandardScalerWrapper LightGBM                 100.0000    0:00:36       0.8333    0.8444\n         4   StandardScalerWrapper LightGBM                 100.0000    0:00:38       0.8444    0.8444\n         5   StandardScalerWrapper ExtremeRandomTrees       100.0000    0:00:36       0.8111    0.8444\n         6   MaxAbsScaler LightGBM                          100.0000    0:00:36       0.8889    0.8889\n         7   StandardScalerWrapper LightGBM                 100.0000    0:00:38       0.8556    0.8889\n         8   MinMaxScaler LightGBM                          100.0000    0:00:39       0.8333    0.8889\n         9   Ensemble                                       100.0000    0:01:01       0.8778    0.8889\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = local_run.get_output()\nprint(best_run)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "azureml.train.automl.utilities.get_primary_metrics('classification')",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "['AUC_weighted',\n 'average_precision_score_weighted',\n 'norm_macro_recall',\n 'precision_score_weighted',\n 'accuracy']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run.continue_experiment(X=X_train,\n                              y=y_train,\n                              X_valid = X_test,\n                              y_valid = y_test,\n                              iterations = 5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "experiment_name = 'automl-titanic_cv'\n# project folder\nproject_folder = './sample_projects/automl-titanic-cv'\n\nexperiment = Experiment(ws, experiment_name)",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_config = AutoMLConfig(task = 'classification',\n                              X=X,\n                              y=y,\n                              primary_metric = 'accuracy',\n                              n_cross_validations = 20,\n                              num_classes = 2,\n                              iterations = 5,\n                              blacklist_models = ['SupportVectorMachine'],\n                              model_explainability=False,\n                              path=project_folder)",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running on local machine\nParent Run ID: AutoML_81d3ce22-9472-44f9-b6c2-e52c6d2e2ec6\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   ",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = local_run.get_output()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(local_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl.automlexplainer import retrieve_model_explanation\n\nshap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n    retrieve_model_explanation(best_run)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(overall_summary)\nprint(overall_imp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fitted_model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "description = 'Titanic'\ntags = None\nlocal_run.register_model(description=description, tags=tags)\nlocal_run.model_id ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\nws = Workspace.from_config()\nfitted_model=Model(ws, 'AutoML3929e9a65best')",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\nimport pickle\nfrom sklearn.externals import joblib\nmodel_path = Model.get_model_path(model_name = 'model.pkl') \n# deserialize the model file back into a sklearn model\nmodel = joblib.load(model_path)\nmodel.predict(X_test)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "array([0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n       0, 0])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\n# Scoring Script\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\n\nfrom azureml.core.model import Model\n\nimport azureml.train.automl\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('AutoML3929e9a65best')\n    print(model_path)\n    model = joblib.load(model_path)\n    \n\ndef run(raw_data):\n    # grab and prepare the data\n    data = np.array(json.loads(raw_data)['data'])\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting score.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies.create(conda_packages=['numpy','lightgbm','scikit-learn'], pip_packages=['azureml-sdk[automl]'])\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open(\"myenv.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  - azureml-sdk[automl]==1.0.17\n- numpy\n- lightgbm\n- sklearn\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n                                               memory_gb=2, \n                                               tags={\"data\": \"Survived\",  \"method\" : \"AutoML\"}, \n                                               description='Predict Survived with Azure AutoML')",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.image import ContainerImage\n\n# configure the image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\")\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='automl-titanic',\n                                       deployment_config=aciconfig,\n                                       models=['AutoML3929e9a65best:1'],\n                                       image_config=image_config)\n\nservice.wait_for_deployment(show_output=True)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\nImage creation operation finished for image automl-titanic:5, operation \"Succeeded\"\nCreating service\nRunning.......................\nSucceededACI service creation operation finished, operation \"Succeeded\"\nCPU times: user 2.19 s, sys: 96.5 ms, total: 2.28 s\nWall time: 8min 4s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ds = ws.get_default_datastore()\nprint(ds.datastore_type, ds.account_name, ds.container_name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import shutil\nos.makedirs(project_folder, exist_ok=True)\nshutil.copy('train.py', project_folder)\nshutil.copy('TitanicTrain.csv', project_folder)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(service.scoring_uri)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "http://52.157.227.238:80/score\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(http://52.157.227.238/swagger.json)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\ninput_data = \"{\\\"data\\\": \" + str(X_test[1:10].values.tolist()) + \"}\" #str(list(X_train[0].reshape(1,-1)[0])) + \"}\"\n\nheaders = {'Content-Type':'application/json'}\nresp = requests.post(service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", service.scoring_uri)\nprint(\"input data:\", input_data)\nprint(\"label:\", y_test[1:10])\nprint(\"prediction:\", resp.text)",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "POST to url http://52.157.227.238:80/score\ninput data: {\"data\": [[2.0, 1.0, 41.0, 2.97092715463502, 0.0, 2.0, 0.0, 0.0], [2.0, 0.0, 42.0, 3.29620716780452, 0.0, 4.0, 0.0, 0.0], [1.0, 0.0, 27.0, 3.2555934078033597, 0.0, 4.0, 1.0, 0.0], [3.0, 0.0, 16.0, 2.08691355651854, 0.0, 4.0, 1.0, 0.0], [3.0, 1.0, 45.0, 3.3289850475482297, 0.0, 2.0, 0.0, 0.0], [1.0, 1.0, 38.0, 5.42730407271175, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 25.0, 2.04898233419513, 2.0, 1.0, 1.0, 0.0], [3.0, 0.0, 27.0, 2.16015709986177, 0.0, 4.0, 1.0, 0.0], [3.0, 1.0, 21.0, 2.04898233419513, 2.0, 1.0, 1.0, 0.0]]}\nlabel: [1 0 0 1 0 1 1 1 1]\nprediction: \"[1, 0, 0, 0, 0, 1, 1, 0, 1]\"\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": 46,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}